{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:04:10.209292Z",
     "iopub.status.busy": "2024-11-02T05:04:10.208511Z",
     "iopub.status.idle": "2024-11-02T05:05:07.617447Z",
     "shell.execute_reply": "2024-11-02T05:05:07.616279Z",
     "shell.execute_reply.started": "2024-11-02T05:04:10.209252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.16.1\n",
      "Uninstalling tensorflow-2.16.1:\n",
      "  Successfully uninstalled tensorflow-2.16.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:05:07.619737Z",
     "iopub.status.busy": "2024-11-02T05:05:07.619386Z",
     "iopub.status.idle": "2024-11-02T05:05:40.772955Z",
     "shell.execute_reply": "2024-11-02T05:05:40.771806Z",
     "shell.execute_reply.started": "2024-11-02T05:05:07.619700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-cpu\n",
      "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.62.2)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-cpu)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-cpu)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-cpu)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-cpu) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-cpu) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\n",
      "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow-cpu\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.3.3\n",
      "    Uninstalling keras-3.3.3:\n",
      "      Successfully uninstalled keras-3.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cloud 0.1.16 requires tensorflow<3.0,>=1.15.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-3.6.0 ml-dtypes-0.4.1 tensorboard-2.18.0 tensorflow-cpu-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:05:40.774703Z",
     "iopub.status.busy": "2024-11-02T05:05:40.774329Z",
     "iopub.status.idle": "2024-11-02T05:05:47.917128Z",
     "shell.execute_reply": "2024-11-02T05:05:47.916283Z",
     "shell.execute_reply.started": "2024-11-02T05:05:40.774667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import BertTokenizer,BertConfig\n",
    "from transformers import BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:05:47.919942Z",
     "iopub.status.busy": "2024-11-02T05:05:47.919323Z",
     "iopub.status.idle": "2024-11-02T05:05:52.643519Z",
     "shell.execute_reply": "2024-11-02T05:05:52.642709Z",
     "shell.execute_reply.started": "2024-11-02T05:05:47.919906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/new-suicide/Suicide_Detection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Bert_API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T04:03:04.312927Z",
     "iopub.status.busy": "2024-11-01T04:03:04.312531Z",
     "iopub.status.idle": "2024-11-01T04:03:04.426256Z",
     "shell.execute_reply": "2024-11-01T04:03:04.425221Z",
     "shell.execute_reply.started": "2024-11-01T04:03:04.312887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# balance dataset pretrain\n",
    "dataset = pd.concat([df[df['class'] == 'suicide'][20000:30000], df[df['class'] == 'non-suicide'][20000:30000]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T04:03:08.342718Z",
     "iopub.status.busy": "2024-11-01T04:03:08.341847Z",
     "iopub.status.idle": "2024-11-01T04:04:46.203607Z",
     "shell.execute_reply": "2024-11-01T04:04:46.202446Z",
     "shell.execute_reply.started": "2024-11-01T04:03:08.342667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# mlm task dataset\n",
    "def prepare_data_for_mlm(df, tokenizer, max_length= 300):\n",
    "  texts = df['text'].tolist()\n",
    "  inputs = tokenizer(texts, max_length=max_length, padding='max_length', truncation=True)\n",
    "  return inputs\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('/kaggle/input/pretrained-v3')\n",
    "train_inputs = prepare_data_for_mlm(dataset, tokenizer)\n",
    "\n",
    "# Create a PyTorch Dataset for MLM\n",
    "class MLMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = MLMDataset(train_inputs)\n",
    "\n",
    "# Create a DataCollator for MLM\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# Create a DataLoader for MLM\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size= 64, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load model pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T04:04:46.206579Z",
     "iopub.status.busy": "2024-11-01T04:04:46.206222Z",
     "iopub.status.idle": "2024-11-01T04:04:46.575090Z",
     "shell.execute_reply": "2024-11-01T04:04:46.574239Z",
     "shell.execute_reply.started": "2024-11-01T04:04:46.206542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load BERT for MLM\n",
    "config = BertConfig.from_pretrained(\"/kaggle/input/pretrained-v3\", num_hidden_layers=1)\n",
    "model = BertForMaskedLM.from_pretrained(\"/kaggle/input/pretrained-v3\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T04:04:46.576714Z",
     "iopub.status.busy": "2024-11-01T04:04:46.576308Z",
     "iopub.status.idle": "2024-11-01T04:04:46.583824Z",
     "shell.execute_reply": "2024-11-01T04:04:46.582929Z",
     "shell.execute_reply.started": "2024-11-01T04:04:46.576661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T04:04:46.586441Z",
     "iopub.status.busy": "2024-11-01T04:04:46.586053Z",
     "iopub.status.idle": "2024-11-01T05:10:01.923257Z",
     "shell.execute_reply": "2024-11-01T05:10:01.922216Z",
     "shell.execute_reply.started": "2024-11-01T04:04:46.586401Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 313/313 [05:55<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Pretrain Loss: 3.517213663734948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 313/313 [05:55<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Pretrain Loss: 3.400194068305409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 313/313 [05:54<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Pretrain Loss: 3.322795727763313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 313/313 [05:55<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Pretrain Loss: 3.2341557059425137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 313/313 [05:55<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Pretrain Loss: 3.183718991355774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 313/313 [05:56<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Pretrain Loss: 3.1404536791121997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 313/313 [05:56<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Pretrain Loss: 3.102560271851171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 313/313 [05:56<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Pretrain Loss: 3.0554085501466695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 313/313 [05:55<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Pretrain Loss: 3.01453208009275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 313/313 [05:55<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Pretrain Loss: 2.9875987177839676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 313/313 [05:55<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Pretrain Loss: 2.9521815761590537\n"
     ]
    }
   ],
   "source": [
    "# convert to GPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# optimizer\n",
    "epochs = 11\n",
    "optimizer = Adam(model.parameters(), lr=0.002)\n",
    "store_loss = {'loss MLM': []}\n",
    "# training\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    if epoch == 10:\n",
    "        model.save_pretrained(\"suicide-bert-pretrained\")\n",
    "        tokenizer.save_pretrained(\"suicide-bert-pretrained\")\n",
    "    store_loss['loss MLM'].append(train_loss / len(train_dataloader))\n",
    "    print(f\"Epoch {epoch + 1}: Pretrain Loss: {train_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* save model pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T05:10:01.924748Z",
     "iopub.status.busy": "2024-11-01T05:10:01.924439Z",
     "iopub.status.idle": "2024-11-01T05:10:02.238526Z",
     "shell.execute_reply": "2024-11-01T05:10:02.237517Z",
     "shell.execute_reply.started": "2024-11-01T05:10:01.924715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('suicide-bert-pretrained-1/tokenizer_config.json',\n",
       " 'suicide-bert-pretrained-1/special_tokens_map.json',\n",
       " 'suicide-bert-pretrained-1/vocab.txt',\n",
       " 'suicide-bert-pretrained-1/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"suicide-bert-pretrained-1\")\n",
    "tokenizer.save_pretrained(\"suicide-bert-pretrained-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T00:35:24.042584Z",
     "iopub.status.busy": "2024-11-02T00:35:24.041892Z",
     "iopub.status.idle": "2024-11-02T00:35:24.167534Z",
     "shell.execute_reply": "2024-11-02T00:35:24.166619Z",
     "shell.execute_reply.started": "2024-11-02T00:35:24.042540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# balance dataset pretrain\n",
    "dataset = pd.concat([df[df['class'] == 'suicide'][:5000], df[df['class'] == 'non-suicide'][:5000]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:05:52.644874Z",
     "iopub.status.busy": "2024-11-02T05:05:52.644593Z",
     "iopub.status.idle": "2024-11-02T05:05:52.667315Z",
     "shell.execute_reply": "2024-11-02T05:05:52.666345Z",
     "shell.execute_reply.started": "2024-11-02T05:05:52.644845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "texts = df['text'].tolist()\n",
    "labels = df['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:33:04.236111Z",
     "iopub.status.busy": "2024-11-02T05:33:04.235414Z",
     "iopub.status.idle": "2024-11-02T05:51:43.621972Z",
     "shell.execute_reply": "2024-11-02T05:51:43.621014Z",
     "shell.execute_reply.started": "2024-11-02T05:33:04.236070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/pretrained-v3\")\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.4)\n",
    "\n",
    "# encoding text\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:51:43.638065Z",
     "iopub.status.busy": "2024-11-02T05:51:43.637689Z",
     "iopub.status.idle": "2024-11-02T05:51:45.015475Z",
     "shell.execute_reply": "2024-11-02T05:51:45.014469Z",
     "shell.execute_reply.started": "2024-11-02T05:51:43.638028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = [1 if label == 'suicide' else 0 for label in labels]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "finetune_dataset = TextDataset(train_encodings, train_labels)\n",
    "val_dataset = TextDataset(val_encodings, val_labels)\n",
    "\n",
    "finetune_loader = DataLoader(finetune_dataset, batch_size= 64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size= 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load model pretrained for finetune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:51:45.025122Z",
     "iopub.status.busy": "2024-11-02T05:51:45.024800Z",
     "iopub.status.idle": "2024-11-02T05:51:45.066723Z",
     "shell.execute_reply": "2024-11-02T05:51:45.065875Z",
     "shell.execute_reply.started": "2024-11-02T05:51:45.025089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/pretrained-v3 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# load pretrained\n",
    "config = BertConfig.from_pretrained(\"/kaggle/input/pretrained-v3\", num_hidden_layers=1,num_labels=2)\n",
    "model = BertForSequenceClassification.from_pretrained(\"/kaggle/input/pretrained-v3\",config = config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T05:51:45.068957Z",
     "iopub.status.busy": "2024-11-02T05:51:45.068674Z",
     "iopub.status.idle": "2024-11-02T09:26:05.858827Z",
     "shell.execute_reply": "2024-11-02T09:26:05.857840Z",
     "shell.execute_reply.started": "2024-11-02T05:51:45.068927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 2176/2176 [17:06<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Training Loss: 0.1482\n",
      "Epoch 1 - Validation Loss: 0.1171 - Accuracy: 0.9565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 2176/2176 [17:04<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Average Training Loss: 0.1007\n",
      "Epoch 2 - Validation Loss: 0.1169 - Accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 2176/2176 [17:08<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Average Training Loss: 0.0819\n",
      "Epoch 3 - Validation Loss: 0.1347 - Accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 2176/2176 [17:08<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Average Training Loss: 0.0671\n",
      "Epoch 4 - Validation Loss: 0.1365 - Accuracy: 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 2176/2176 [17:12<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Average Training Loss: 0.0520\n",
      "Epoch 5 - Validation Loss: 0.1861 - Accuracy: 0.9527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 2176/2176 [17:12<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Average Training Loss: 0.0432\n",
      "Epoch 6 - Validation Loss: 0.2072 - Accuracy: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 2176/2176 [17:12<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Average Training Loss: 0.0351\n",
      "Epoch 7 - Validation Loss: 0.1870 - Accuracy: 0.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 2176/2176 [17:14<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Average Training Loss: 0.0293\n",
      "Epoch 8 - Validation Loss: 0.2151 - Accuracy: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 2176/2176 [17:16<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Average Training Loss: 0.0272\n",
      "Epoch 9 - Validation Loss: 0.2011 - Accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 2176/2176 [17:18<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Average Training Loss: 0.0210\n",
      "Epoch 10 - Validation Loss: 0.1936 - Accuracy: 0.9496\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = Adam(model.parameters(), lr=2e-3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(finetune_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = train_loss / len(finetune_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # evaluate \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (preds == batch['labels']).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = correct / len(val_dataset)\n",
    "    print(f\"Epoch {epoch + 1} - Validation Loss: {avg_val_loss:.4f} - Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T09:26:05.860355Z",
     "iopub.status.busy": "2024-11-02T09:26:05.860024Z",
     "iopub.status.idle": "2024-11-02T09:26:06.449724Z",
     "shell.execute_reply": "2024-11-02T09:26:06.448681Z",
     "shell.execute_reply.started": "2024-11-02T09:26:05.860290Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert-classify-model/tokenizer_config.json',\n",
       " 'bert-classify-model/special_tokens_map.json',\n",
       " 'bert-classify-model/vocab.txt',\n",
       " 'bert-classify-model/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"bert-classify-model\")\n",
    "tokenizer.save_pretrained(\"bert-classify-model\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5983637,
     "sourceId": 9769474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5983663,
     "sourceId": 9769506,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5989283,
     "sourceId": 9776963,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30788,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
