{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from suicide_data import SuicideDataset\n",
    "from torch.utils.data import  DataLoader\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from utils import sketch,precision_recall_f1,accuracy_cal,map_to_labels\n",
    "import copy\n",
    "from model.attention_bilstm import BiLSTM_Attention\n",
    "from model.lstm import SentimentLSTM\n",
    "from model.rnn import SentimentRNN\n",
    "from model.gru import GRU\n",
    "from model.cnn import CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration,data,pretrained embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    lstm_config = config['LSTM']\n",
    "    bilstm_config = config['BiLSTM_Attention']\n",
    "    rnn_config = config['RNN']\n",
    "    gru_config = config['GRU']\n",
    "    cnn_config = config['CNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training data\n",
    "train_df = pd.read_csv(\"data/train_data.csv\")\n",
    "#Load validation data\n",
    "val_df = pd.read_csv(\"data/val_data.csv\")\n",
    "#Load tokenizer object\n",
    "with open(\"embeddings/tokenizer.json\", \"r\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "with open(\"embeddings/CBOW_embeddings.pkl\" , \"rb\") as cbow:\n",
    "    cbow_embeddings = pickle.load(cbow)\n",
    "with open(\"embeddings/SkipGram_embeddings.pkl\" , \"rb\") as sg:\n",
    "    sg_embeddings = pickle.load(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SuicideDataset(texts = train_df[\"cleaned_text\"], labels = train_df[\"class\"], tokenizer = tokenizer)\n",
    "valset = SuicideDataset(val_df[\"cleaned_text\"], val_df[\"class\"], tokenizer)\n",
    "train_loader = DataLoader(trainset, batch_size= 64,shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(valset, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=len(tokenizer.index_word)+1\n",
    "# Load the pre-trained Word2Vec model (e.g., Google News vectors)\n",
    "w2v_model = Word2Vec(sentences=common_texts, vector_size=300, window=5, min_count=1, workers=4)\n",
    "embedding_dim = w2v_model.vector_size  \n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, embedding_dim))\n",
    "#Creating thw embedding_matrix based on W2V model in gensim\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]  \n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and Experimental results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common train function for all model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs, learning_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "\n",
    "    # Track best metrics\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    best_metrics = []  # List to store all the best metrics in one place\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_acc = 0\n",
    "        total_train_f1 = 0\n",
    "\n",
    "        # Training phase\n",
    "        for step, (batch_embeddings, batch_labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "\n",
    "            tag_scores = model(batch_embeddings)\n",
    "            loss = criterion(tag_scores, batch_labels.float())\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            acc = accuracy_cal(tag_scores, batch_labels.float())\n",
    "            total_train_acc += acc\n",
    "\n",
    "            f1 = precision_recall_f1(tag_scores, batch_labels.float())[2]\n",
    "            total_train_f1 += f1\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_acc = total_train_acc / len(train_loader)\n",
    "        avg_train_f1 = total_train_f1 / len(train_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accs.append(avg_train_acc)\n",
    "        train_f1s.append(avg_train_f1)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "        total_val_f1 = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_embeddings, batch_labels in val_loader:\n",
    "                batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "                val_outputs = model(batch_embeddings)\n",
    "\n",
    "                val_loss = criterion(val_outputs, batch_labels.float())\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                val_acc = accuracy_cal(val_outputs, batch_labels.float())\n",
    "                total_val_acc += val_acc\n",
    "\n",
    "                val_f1 = precision_recall_f1(val_outputs, batch_labels.float())[2]\n",
    "                total_val_f1 += val_f1\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_acc = total_val_acc / len(val_loader)\n",
    "        avg_val_f1 = total_val_f1 / len(val_loader)\n",
    "\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accs.append(avg_val_acc)\n",
    "        val_f1s.append(avg_val_f1)\n",
    "\n",
    "        # Update best metrics if current validation loss is better\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_metrics = [\n",
    "                best_epoch, avg_train_loss, best_val_loss,\n",
    "                avg_train_acc, avg_val_acc,\n",
    "                avg_train_f1, avg_val_f1\n",
    "            ]\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, '\n",
    "              f'Train Accuracy: {avg_train_acc:.4f}%, Val Accuracy: {avg_val_acc:.4f}%, '\n",
    "              f'Train F1-Score: {avg_train_f1:.4f}%, Val F1-Score: {avg_val_f1:.4f}%')\n",
    "\n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"\\nTraining complete!\")\n",
    "\n",
    "    print(f\"Best Model at Epoch {best_metrics[0]}: \"\n",
    "          f\"Train Loss: {best_metrics[1]:.4f}, Val Loss: {best_metrics[2]:.4f}, \"\n",
    "          f\"Train Accuracy: {best_metrics[3]:.4f}%, Val Accuracy: {best_metrics[4]:.4f}%, \"\n",
    "          f\"Train F1-Score: {best_metrics[5]:.4f}%, Val F1-Score: {best_metrics[6]:.4f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, train_f1s, val_f1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate'],\n",
    "    pretrained_embeddings=  cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN with CBOW model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with Skip Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate'],\n",
    "    pretrained_embeddings=  sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN with SkipGram model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate'],\n",
    "    pretrained_embeddings = embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate'],\n",
    "    pretrained_embeddings= cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate'],\n",
    "    pretrained_embeddings= sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM with SkipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM with Attenion Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention without preprocessing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention with SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention with SKipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate'],\n",
    "    pretrained_embeddings= cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU with SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate'],\n",
    "    pretrained_embeddings= sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU with SKipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate'],\n",
    "    pretrained_embeddings= embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.3186, Val Loss: 0.2306, Train Accuracy: 0.8677%, Val Accuracy: 0.9107%, Train F1-Score: 0.8651%, Val F1-Score: 0.9088%\n",
      "Epoch [2/15], Train Loss: 0.2353, Val Loss: 0.2119, Train Accuracy: 0.9087%, Val Accuracy: 0.9189%, Train F1-Score: 0.9068%, Val F1-Score: 0.9176%\n",
      "Epoch [3/15], Train Loss: 0.2097, Val Loss: 0.2030, Train Accuracy: 0.9196%, Val Accuracy: 0.9229%, Train F1-Score: 0.9179%, Val F1-Score: 0.9222%\n",
      "Epoch [4/15], Train Loss: 0.1923, Val Loss: 0.2003, Train Accuracy: 0.9272%, Val Accuracy: 0.9247%, Train F1-Score: 0.9258%, Val F1-Score: 0.9247%\n",
      "Epoch [5/15], Train Loss: 0.1785, Val Loss: 0.1938, Train Accuracy: 0.9332%, Val Accuracy: 0.9272%, Train F1-Score: 0.9319%, Val F1-Score: 0.9260%\n",
      "Epoch [6/15], Train Loss: 0.1670, Val Loss: 0.1926, Train Accuracy: 0.9373%, Val Accuracy: 0.9279%, Train F1-Score: 0.9361%, Val F1-Score: 0.9272%\n",
      "Epoch [7/15], Train Loss: 0.1550, Val Loss: 0.1938, Train Accuracy: 0.9421%, Val Accuracy: 0.9277%, Train F1-Score: 0.9411%, Val F1-Score: 0.9273%\n",
      "Epoch [8/15], Train Loss: 0.1467, Val Loss: 0.1936, Train Accuracy: 0.9454%, Val Accuracy: 0.9286%, Train F1-Score: 0.9445%, Val F1-Score: 0.9281%\n",
      "Epoch [9/15], Train Loss: 0.1369, Val Loss: 0.1939, Train Accuracy: 0.9491%, Val Accuracy: 0.9289%, Train F1-Score: 0.9483%, Val F1-Score: 0.9281%\n",
      "Epoch [10/15], Train Loss: 0.1283, Val Loss: 0.1946, Train Accuracy: 0.9530%, Val Accuracy: 0.9297%, Train F1-Score: 0.9522%, Val F1-Score: 0.9286%\n",
      "Epoch [11/15], Train Loss: 0.1217, Val Loss: 0.1975, Train Accuracy: 0.9550%, Val Accuracy: 0.9296%, Train F1-Score: 0.9544%, Val F1-Score: 0.9290%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39mCNN(\n\u001b[0;32m      2\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m VOCAB_SIZE,\n\u001b[0;32m      3\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m cnn_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m cnn_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 8\u001b[0m train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcnn_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcnn_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m sketch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN without preprocessing model\u001b[39m\u001b[38;5;124m\"\u001b[39m,train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)\n",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     24\u001b[0m total_train_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:317\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    171\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:223\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\84359\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:214\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    212\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    213\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model =CNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= cnn_config[\"embedding_dim\"],\n",
    "    num_filters= cnn_config[\"num_filters\"],\n",
    "    filter_sizes= cnn_config[\"filter_sizes\"],\n",
    "    dropout= cnn_config[\"dropout_rate\"],\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,cnn_config['epochs'],cnn_config['learning_rate'])\n",
    "sketch(\"CNN without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.4695, Val Loss: 0.4392, Train Accuracy: 0.7898%, Val Accuracy: 0.8056%, Train F1-Score: 0.7851%, Val F1-Score: 0.7939%\n",
      "Epoch [2/15], Train Loss: 0.4440, Val Loss: 0.4359, Train Accuracy: 0.8027%, Val Accuracy: 0.8062%, Train F1-Score: 0.7915%, Val F1-Score: 0.7964%\n",
      "Epoch [3/15], Train Loss: 0.4418, Val Loss: 0.4353, Train Accuracy: 0.8040%, Val Accuracy: 0.8069%, Train F1-Score: 0.7926%, Val F1-Score: 0.7947%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39mCNN(\n\u001b[0;32m      2\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m VOCAB_SIZE,\n\u001b[0;32m      3\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m cnn_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     embedding_matrix\u001b[38;5;241m=\u001b[39m cbow_embeddings\n\u001b[0;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcnn_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcnn_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m sketch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN with CBOW\u001b[39m\u001b[38;5;124m\"\u001b[39m,train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     35\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_cal(tag_scores, batch_labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     36\u001b[0m total_train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n\u001b[1;32m---> 38\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_f1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     39\u001b[0m total_train_f1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m f1\n\u001b[0;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\python\\HUST-SuicideDetection-DeepLearning\\utils.py:22\u001b[0m, in \u001b[0;36mprecision_recall_f1\u001b[1;34m(preds, labels)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Iterate over batches\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m preds, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(mapped_preds, labels):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# True Positives (TP)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     TP \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# False Positives (FP)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     FP \u001b[38;5;241m=\u001b[39m ((preds \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model =CNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= cnn_config[\"embedding_dim\"],\n",
    "    num_filters= cnn_config[\"num_filters\"],\n",
    "    filter_sizes= cnn_config[\"filter_sizes\"],\n",
    "    dropout= cnn_config[\"dropout_rate\"],\n",
    "    embedding_matrix= cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,cnn_config['epochs'],cnn_config['learning_rate'])\n",
    "sketch(\"CNN with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with SkipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =CNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= cnn_config[\"embedding_dim\"],\n",
    "    num_filters= cnn_config[\"num_filters\"],\n",
    "    filter_sizes= cnn_config[\"filter_sizes\"],\n",
    "    dropout= cnn_config[\"dropout_rate\"],\n",
    "    embedding_matrix= sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,cnn_config['epochs'],cnn_config['learning_rate'])\n",
    "sketch(\"CNN with SkipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.3268, Val Loss: 0.2446, Train Accuracy: 0.8633%, Val Accuracy: 0.9041%, Train F1-Score: 0.8633%, Val F1-Score: 0.9021%\n",
      "Epoch [2/15], Train Loss: 0.2454, Val Loss: 0.2231, Train Accuracy: 0.9042%, Val Accuracy: 0.9138%, Train F1-Score: 0.9019%, Val F1-Score: 0.9125%\n",
      "Epoch [3/15], Train Loss: 0.2221, Val Loss: 0.2137, Train Accuracy: 0.9137%, Val Accuracy: 0.9182%, Train F1-Score: 0.9116%, Val F1-Score: 0.9170%\n",
      "Epoch [4/15], Train Loss: 0.2059, Val Loss: 0.2074, Train Accuracy: 0.9204%, Val Accuracy: 0.9206%, Train F1-Score: 0.9186%, Val F1-Score: 0.9191%\n",
      "Epoch [5/15], Train Loss: 0.1944, Val Loss: 0.2026, Train Accuracy: 0.9255%, Val Accuracy: 0.9227%, Train F1-Score: 0.9237%, Val F1-Score: 0.9208%\n",
      "Epoch [6/15], Train Loss: 0.1844, Val Loss: 0.2006, Train Accuracy: 0.9299%, Val Accuracy: 0.9231%, Train F1-Score: 0.9285%, Val F1-Score: 0.9213%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39mCNN(\n\u001b[0;32m      2\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m VOCAB_SIZE,\n\u001b[0;32m      3\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m cnn_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     embedding_matrix\u001b[38;5;241m=\u001b[39m embedding_matrix\n\u001b[0;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcnn_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcnn_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m sketch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN with pretrained W2V in Gensim\u001b[39m\u001b[38;5;124m\"\u001b[39m,train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)\n",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     35\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_cal(tag_scores, batch_labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     36\u001b[0m total_train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n\u001b[1;32m---> 38\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_f1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     39\u001b[0m total_train_f1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m f1\n\u001b[0;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\python\\HUST-SuicideDetection-DeepLearning\\utils.py:22\u001b[0m, in \u001b[0;36mprecision_recall_f1\u001b[1;34m(preds, labels)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Iterate over batches\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m preds, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(mapped_preds, labels):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# True Positives (TP)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     TP \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# False Positives (FP)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     FP \u001b[38;5;241m=\u001b[39m ((preds \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model =CNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= cnn_config[\"embedding_dim\"],\n",
    "    num_filters= cnn_config[\"num_filters\"],\n",
    "    filter_sizes= cnn_config[\"filter_sizes\"],\n",
    "    dropout= cnn_config[\"dropout_rate\"],\n",
    "    embedding_matrix= embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,cnn_config['epochs'],cnn_config['learning_rate'])\n",
    "sketch(\"CNN with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
