{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from suicide_data import SuicideDataset\n",
    "from torch.utils.data import  DataLoader\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from utils import sketch,precision_recall_f1,accuracy_cal,map_to_labels\n",
    "import copy\n",
    "from model.attention_bilstm import BiLSTM_Attention\n",
    "from model.lstm import SentimentLSTM\n",
    "from model.rnn import SentimentRNN\n",
    "from model.gru import GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load configuration,data,pretrained embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    lstm_config = config['LSTM']\n",
    "    bilstm_config = config['BiLSTM_Attention']\n",
    "    rnn_config = config['RNN']\n",
    "    gru_config = config['GRU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training data\n",
    "train_df = pd.read_csv(\"data/train_data.csv\")\n",
    "#Load validation data\n",
    "val_df = pd.read_csv(\"data/val_data.csv\")\n",
    "#Load tokenizer object\n",
    "with open(\"embeddings/tokenizer.json\", \"r\") as f:\n",
    "    tokenizer_json = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
    "with open(\"embeddings/CBOW_embeddings.pkl\" , \"rb\") as cbow:\n",
    "    cbow_embeddings = pickle.load(cbow)\n",
    "with open(\"embeddings/SkipGram_embeddings.pkl\" , \"rb\") as sg:\n",
    "    sg_embeddings = pickle.load(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SuicideDataset(texts = train_df[\"cleaned_text\"], labels = train_df[\"class\"], tokenizer = tokenizer)\n",
    "valset = SuicideDataset(val_df[\"cleaned_text\"], val_df[\"class\"], tokenizer)\n",
    "train_loader = DataLoader(trainset, batch_size= 64,shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(valset, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=len(tokenizer.index_word)+1\n",
    "# Load the pre-trained Word2Vec model (e.g., Google News vectors)\n",
    "w2v_model = Word2Vec(sentences=common_texts, vector_size=300, window=5, min_count=1, workers=4)\n",
    "embedding_dim = w2v_model.vector_size  \n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, embedding_dim))\n",
    "#Creating thw embedding_matrix based on W2V model in gensim\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]  \n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and Experimental results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common train function for all model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs, learning_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "\n",
    "    # Track best metrics\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    best_metrics = []  # List to store all the best metrics in one place\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_acc = 0\n",
    "        total_train_f1 = 0\n",
    "\n",
    "        # Training phase\n",
    "        for step, (batch_embeddings, batch_labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "\n",
    "            tag_scores = model(batch_embeddings)\n",
    "            loss = criterion(tag_scores, batch_labels.float())\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            acc = accuracy_cal(tag_scores, batch_labels.float())\n",
    "            total_train_acc += acc\n",
    "\n",
    "            f1 = precision_recall_f1(tag_scores, batch_labels.float())[2]\n",
    "            total_train_f1 += f1\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_acc = total_train_acc / len(train_loader)\n",
    "        avg_train_f1 = total_train_f1 / len(train_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accs.append(avg_train_acc)\n",
    "        train_f1s.append(avg_train_f1)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "        total_val_f1 = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_embeddings, batch_labels in val_loader:\n",
    "                batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "                val_outputs = model(batch_embeddings)\n",
    "\n",
    "                val_loss = criterion(val_outputs, batch_labels.float())\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                val_acc = accuracy_cal(val_outputs, batch_labels.float())\n",
    "                total_val_acc += val_acc\n",
    "\n",
    "                val_f1 = precision_recall_f1(val_outputs, batch_labels.float())[2]\n",
    "                total_val_f1 += val_f1\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_acc = total_val_acc / len(val_loader)\n",
    "        avg_val_f1 = total_val_f1 / len(val_loader)\n",
    "\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accs.append(avg_val_acc)\n",
    "        val_f1s.append(avg_val_f1)\n",
    "\n",
    "        # Update best metrics if current validation loss is better\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_metrics = [\n",
    "                best_epoch, avg_train_loss, best_val_loss,\n",
    "                avg_train_acc, avg_val_acc,\n",
    "                avg_train_f1, avg_val_f1\n",
    "            ]\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, '\n",
    "              f'Train Accuracy: {avg_train_acc:.4f}%, Val Accuracy: {avg_val_acc:.4f}%, '\n",
    "              f'Train F1-Score: {avg_train_f1:.4f}%, Val F1-Score: {avg_val_f1:.4f}%')\n",
    "\n",
    "    # Load the best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"\\nTraining complete!\")\n",
    "\n",
    "    print(f\"Best Model at Epoch {best_metrics[0]}: \"\n",
    "          f\"Train Loss: {best_metrics[1]:.4f}, Val Loss: {best_metrics[2]:.4f}, \"\n",
    "          f\"Train Accuracy: {best_metrics[3]:.4f}%, Val Accuracy: {best_metrics[4]:.4f}%, \"\n",
    "          f\"Train F1-Score: {best_metrics[5]:.4f}%, Val F1-Score: {best_metrics[6]:.4f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, train_f1s, val_f1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate'],\n",
    "    pretrained_embeddings=  cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN with CBOW model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with Skip Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate'],\n",
    "    pretrained_embeddings=  sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN with SkipGram model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentRNN(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= rnn_config[\"embedding_dim\"],\n",
    "    hidden_size=rnn_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=rnn_config[\"num_layers\"],\n",
    "    dropout_rate=rnn_config['dropout_rate'],\n",
    "    pretrained_embeddings = embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,rnn_config['epochs'],rnn_config['learning_rate'])\n",
    "sketch(\"RNN with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate'],\n",
    "    pretrained_embeddings= cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate'],\n",
    "    pretrained_embeddings= sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM with SkipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentLSTM(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= lstm_config[\"embedding_dim\"],\n",
    "    hidden_size=lstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=lstm_config[\"num_layers\"],\n",
    "    dropout_rate=lstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,lstm_config['epochs'],lstm_config['learning_rate'])\n",
    "sketch(\"LSTM with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM with Attenion Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention without preprocessing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention with SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention with SKipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BI-LSTM_Attention with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =BiLSTM_Attention(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= bilstm_config[\"embedding_dim\"],\n",
    "    hidden_size=bilstm_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=bilstm_config[\"num_layers\"],\n",
    "    dropout_rate=bilstm_config['dropout_rate'],\n",
    "    pretrained_embeddings=embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,bilstm_config['epochs'],bilstm_config['learning_rate'])\n",
    "sketch(\"BI-LSTM_Attention with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU without preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate']\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU without preprocessing model\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU with CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate'],\n",
    "    pretrained_embeddings= cbow_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU with CBOW\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU with SKipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate'],\n",
    "    pretrained_embeddings= sg_embeddings\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU with SKipGram\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU with pretrained W2V in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =GRU(\n",
    "    vocab_size= VOCAB_SIZE,\n",
    "    embedding_dim= gru_config[\"embedding_dim\"],\n",
    "    hidden_size=gru_config[\"hidden_size\"],\n",
    "    tagset_size=1,\n",
    "    n_layers=gru_config[\"num_layers\"],\n",
    "    dropout_rate=gru_config['dropout_rate'],\n",
    "    pretrained_embeddings= embedding_matrix\n",
    ").to(device)\n",
    "train_losses,val_losses,train_accs,val_accs, train_f1, val_f1 = train(model, train_loader,val_loader,gru_config['epochs'],gru_config['learning_rate'])\n",
    "sketch(\"GRU with pretrained W2V in Gensim\",train_losses,val_losses,train_accs,val_accs, train_f1, val_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
